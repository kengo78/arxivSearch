{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f9acf-1c77-4d86-ab4b-da4584e1a179",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'Python 3.9.5 ('Mail_automation-LurfJT-x')' を使用した実行中のセルには ipykernel パッケージが必要です。\n",
      "\u001b[1;31m次のコマンドを実行して、'ipykernel' を Python 環境にインストールします。\n",
      "\u001b[1;31mコマンド: '/Users/exidea258/.local/share/virtualenvs/Mail_automation-LurfJT-x/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "177f22af-5c8e-4385-806a-fa2257a4c061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Downloading arxiv-1.4.2-py3-none-any.whl (11 kB)\n",
      "Collecting feedparser\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=d8bc0216451ea61bbd7a043000fc43903e4fbdee00045a7af19184fa14a5f616\n",
      "  Stored in directory: /Users/exidea258/Library/Caches/pip/wheels/83/63/2f/117884c3b19d46b64d3d61690333aa80c88dc14050e269c546\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-1.4.2 feedparser-6.0.10 sgmllib3k-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b334d24e-f85d-451d-9b69-a0ef1e6bf8f7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==4.0.0-rc1 in /opt/anaconda3/lib/python3.8/site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in /opt/anaconda3/lib/python3.8/site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: chardet==3.* in /opt/anaconda3/lib/python3.8/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.8/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
      "Requirement already satisfied: idna==2.* in /opt/anaconda3/lib/python3.8/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /opt/anaconda3/lib/python3.8/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.8/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.5.18.1)\n",
      "Requirement already satisfied: httpcore==0.9.* in /opt/anaconda3/lib/python3.8/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: hstspreload in /opt/anaconda3/lib/python3.8/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.9.1)\n",
      "Requirement already satisfied: h2==3.* in /opt/anaconda3/lib/python3.8/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /opt/anaconda3/lib/python3.8/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /opt/anaconda3/lib/python3.8/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install arxiv\n",
    "# !pip install pytz\n",
    "!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc7706b4-93e4-4be5-9477-92b65fa97d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import time\n",
    "import pytz\n",
    "import datetime\n",
    "\n",
    "dt_now = datetime.datetime.now(pytz.timezone('Asia/Tokyo'))\n",
    "dt_old = dt_now - datetime.timedelta(days=7)\n",
    "dt_all = dt_old.strftime('%Y%m%d%H%M%S')\n",
    "dt_day = dt_old.strftime('%Y%m%d')\n",
    "dt_hour = dt_old.strftime('%H')\n",
    "if dt_hour == '00':\n",
    "            dt_last = dt_day + '115959'\n",
    "            cv_papers = arxiv.Search(\n",
    "              query = \"cat:cs.IT AND submittedDate:[{} TO {}]\".format(dt_day, dt_last),\n",
    "              max_results = 100,\n",
    "              sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "            )\n",
    "else:\n",
    "    dt_last = dt_day + '235959'\n",
    "    cv_papers = arxiv.Search(\n",
    "      query = \"cat:cs.IT AND submittedDate:[{} TO {}]\".format(dt_day, dt_last),\n",
    "      max_results = 100,\n",
    "      sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "476caca7-bd47-4711-a9c4-49d14cf5a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b83c8ace-59f7-4a24-b820-9384c24ff583",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When a machine-learning algorithm makes biased decisions, it can be helpfulto understand the sources of disparity to explain why the bias exists. Towardsthis, we examine the problem of quantifying the contribution of each individualfeature to the observed disparity. If we have access to the decision-makingmodel, one potential approach (inspired from intervention-based approaches inexplainability literature) is to vary each individual feature (while keepingthe others fixed) and use the resulting change in disparity to quantify itscontribution. However, we may not have access to the model or be able totest/audit its outputs for individually varying features. Furthermore, thedecision may not always be a deterministic function of the input features(e.g., with human-in-the-loop). For these situations, we might need to explaincontributions using purely distributional (i.e., observational) techniques,rather than interventional. We ask the question: what is the \"potential\"contribution of each individual feature to the observed disparity in thedecisions when the exact decision-making mechanism is not accessible? We firstprovide canonical examples (thought experiments) that help illustrate thedifference between distributional and interventional approaches to explainingcontributions, and when either is better suited. When unable to intervene onthe inputs, we quantify the \"redundant\" statistical dependency about theprotected attribute that is present in both the final decision and anindividual feature, by leveraging a body of work in information theory calledPartial Information Decomposition. We also perform a simple case study to showhow this technique could be applied to quantify contributions.\n",
      "Late visions and trends for the future sixth Generation (6G) of wirelesscommunications advocate, among other technologies, towards the deployment ofnetwork nodes with extreme numbers of antennas and up to terahertz frequencies,as means to enable various immersive applications. However, these technologiesimpose several challenges in the design of radio-frequency front-ends andbeamforming architectures, as well as of ultra-wideband waveforms andcomputationally efficient transceiver signal processing. In this article, werevisit the Time Reversal (TR) technique, which was initially experimented inacoustics, in the context of large-bandwidth 6G wireless communications,capitalizing on its high resolution spatiotemporal focusing realized with lowcomplexity transceivers. We first overview representative state-of-the-art inTR-based wireless communications, identifying the key competencies andrequirements of TR for efficient operation. Recent and novel experimentalsetups and results for the spatiotemporal focusing capability of TR at thecarrier frequencies $2.5$, $36$, and $273$ GHz are then presented,demonstrating in quantitative ways the technique's effectiveness in these verydifferent frequency bands, as well as the roles of the available bandwidth andthe number of transmit antennas. We also showcase the TR potential forrealizing low complexity multi-user communications. The opportunities arisingfrom TR-based wireless communications as well as the challenges for findingtheir place in 6G networks, also in conjunction with other complementarycandidate technologies, are highlighted.\n",
      "Variational quantum algorithms have been acknowledged as a leading strategyto realize near-term quantum advantages in meaningful tasks, including machinelearning and combinatorial optimization. When applied to tasks involvingclassical data, such algorithms generally begin with quantum circuits for dataencoding and then train quantum neural networks (QNNs) to minimize targetfunctions. Although QNNs have been widely studied to improve these algorithms'performance on practical tasks, there is a gap in systematically understandingthe influence of data encoding on the eventual performance. In this paper, wemake progress in filling this gap by considering the common data encodingstrategies based on parameterized quantum circuits. We prove that, underreasonable assumptions, the distance between the average encoded state and themaximally mixed state could be explicitly upper-bounded with respect to thewidth and depth of the encoding circuit. This result in particular implies thatthe average encoded state will concentrate on the maximally mixed state at anexponential speed on depth. Such concentration seriously limits thecapabilities of quantum classifiers, and strictly restricts thedistinguishability of encoded states from a quantum information perspective. Wefurther support our findings by numerically verifying these results on bothsynthetic and public data sets. Our results highlight the significance ofquantum data encoding in machine learning tasks and may shed light on futureencoding strategies.\n",
      "This paper considers the downlink of a single-cell massive MIMO(multiple-input multiple-output) system with dual-polarized antennas at boththe base station and users. We consider a channel model that takes into accountseveral practical aspects that arise when utilizing dual polarization, such aschannel cross-polar discrimination (XPD) and cross-polar receive and transmitcorrelations (XPC). We derive the statistical properties of the minimum meansquared error (MMSE) channel estimator for this model. Using these estimatesfor maximum ratio precoding, a rigorous closed-form downlink spectralefficiency (SE) expression is derived. We compare the SEs achieved indual-polarized and uni-polarized setups numerically and evaluate the impact ofXPD on the downlink SE.\n",
      "The rapid development of DNA storage has brought the deletion and insertionchannel to the front line of research. When the number of deletions is equal tothe number of insertions, the Fixed Length Levenshtein (FLL) metric is theright measure for the distance between two words of the same length. Similar toany other metric, the size of a ball is one of the most fundamental parameters.In this work, we consider the minimum, maximum, and average size of a ball withradius one, in the FLL metric. The related minimum and the maximum size of amaximal anticode with diameter one are also considered.\n",
      "Reconfigurable intelligent surface (RIS) has emerged as a cost-effective andenergy-efficient technique for 6G. By adjusting the phase shifts of passivereflecting elements, RIS is capable of suppressing the interference andcombining the desired signals constructively at receivers, therebysignificantly enhancing the performance of communication In this paper, weconsider a green multi-user multi-antenna cellular network, where multiple RISsare deployed to provide energy-efficient communication service to end users. Wejointly optimize the phase shifts of RISs, beamforming of the base stations,and the active RIS set with the aim of minimizing the power consumption of thebase station (BS) and RISs subject to the quality of service (QoS) constraintsof users and the transmit power constraint of the BS. However, the problem ismixed combinatorial and nonconvex, and there is a potential infeasibility issuewhen the QoS constraints cannot be guaranteed by all users. To deal with theinfeasibility issue, we further investigate a user admission control problem tojointly optimize the transmit beamforming, RIS phase shifts, and the admitteduser set. A unified alternating optimization (AO) framework is then proposed tosolve both the power minimization and user admission control problems.Specifically, we first decompose the original nonconvex problem into severalrank-one constrained optimization subproblems via matrix lifting. The proposedAO framework efficiently minimizes the power consumption of wireless networksas well as user admission control when the QoS constraints cannot be guaranteedby all users. Compared with the baseline algorithms, we illustrate that theproposed algorithm can achieve lower power consumption for given QoSconstraints. Most importantly, the proposed algorithm successfully addressesthe infeasibility issue with a QoS guarantee for active users.\n",
      "The Convex Gaussian Min-Max Theorem (CGMT) has emerged as a prominenttheoretical tool for analyzing the precise stochastic behavior of variousstatistical estimators in the so-called high dimensional proportional regime,where the sample size and the signal dimension are of the same order. However,a well recognized limitation of the existing CGMT machinery rests in itsstringent requirement on the exact Gaussianity of the design matrix, thereforerendering the obtained precise high dimensional asymptotics largely a specificGaussian theory in various important statistical models.  This paper provides a structural universality framework for a broad class ofregularized regression estimators that is particularly compatible with the CGMTmachinery. In particular, we show that with a good enough $\\ell_\\infty$ boundfor the regression estimator $\\hat{\\mu}_A$, any `structural property' that canbe detected via the CGMT for $\\hat{\\mu}_G$ (under a standard Gaussian design$G$) also holds for $\\hat{\\mu}_A$ under a general design $A$ with independententries. As a proof of concept, we demonstrate our new universality frameworkin three key examples of regularized regression estimators: the Ridge, Lassoand regularized robust regression estimators, where new universality propertiesof risk asymptotics and/or distributions of regression estimators and otherrelated quantities are proved. As a major statistical implication of the Lassouniversality results, we validate inference procedures using thedegrees-of-freedom adjusted debiased Lasso under general design and errordistributions. We also provide a counterexample, showing that universalityproperties for regularized regression estimators do not extend to generalisotropic designs.\n",
      "Though originally developed for communications engineering, informationtheory contains mathematical tools with numerous applications in science andengineering. These tools can be used to characterize the fundamental limits ofdata compression and transmission in the presence of noise. Here, we present apractical guide to key concepts in information theory, focusing on intuitionsand providing visual explanations wherever possible. Our presentation assumesonly a familiarity with basic probability theory.\n"
     ]
    }
   ],
   "source": [
    "for cv_paper in cv_papers.results():\n",
    "    title = cv_paper.title\n",
    "    pdf = cv_paper.pdf_url\n",
    "    summary = cv_paper.summary\n",
    "    summary = ''.join(summary.splitlines())\n",
    "#     summary_ja = translator.translate(summary, src='en', dest='ja')\n",
    "#     summary_ja = str(summary_ja.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7dbb6c37-7541-4929-b781-80cb0fd4103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Though originally developed for communications engineering, informationtheory contains mathematical tools with numerous applications in science andengineering. These tools can be used to characterize the fundamental limits ofdata compression and transmission in the presence of noise. Here, we present apractical guide to key concepts in information theory, focusing on intuitionsand providing visual explanations wherever possible. Our presentation assumesonly a familiarity with basic probability theory.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aea04641-5626-47e7-9426-a0b7b4a72445",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-55577a409a38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ja'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/googletrans/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mLANGCODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLANGCODES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid source language'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/googletrans/client.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src, override)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEFAULT_FALLBACK_SERVICE_URLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/googletrans/gtoken.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: nocover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m2147483647\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2147483648\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m%=\u001b[0m \u001b[0;36m1000000\u001b[0m  \u001b[0;31m# int(1E6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'{}.{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/googletrans/gtoken.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;31m# this will be the same as python code after stripping out a reserved word 'var'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRE_TKK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'var '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# unescape special ascii characters such like a \\x3d(=)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "translator.translate(summary, dest='ja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1940eb9-8ca2-4002-afd2-655868f5d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "  query = \"cat:cs.IT AND submittedDate:[{} TO {}]\".format(dt_day, dt_last),\n",
    "  max_results = 10,\n",
    "  sort_by = arxiv.SortCriterion.SubmittedDate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a02f90b-be60-45ad-8e23-ccd71944f3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2x2 MIMO Prototype for BER and EVM Measurements in Metal Enclosure\n"
     ]
    }
   ],
   "source": [
    "for result in search.results():\n",
    "    print(result.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c179efaa-19ab-4795-8bee-aefc42ea828f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd5b6b7-f756-4534-b1b9-9a708fd4fcea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('Mail_automation-LurfJT-x')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f495d86534feb6c1f0a544cd1d80ee6c42949da846ec95c1728831c2d4b3013a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
